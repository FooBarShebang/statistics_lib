# Test Report on the Module statistics_lib.distribution_classes

## Conventions

Each test is defined following the same format. Each test receives a unique test identifier and a reference to the ID(s) of the requirements it covers (if applicable). The goal of the test is described to clarify what is to be tested. The test steps are described in brief but clear instructions. For each test it is defined what the expected results are for the test to pass. Finally, the test result is given, this can be only pass or fail.

The test format is as follows:

**Test Identifier:** TEST-\[I/A/D/T\]-XYZ

**Requirement ID(s)**: REQ-uvw-xyz

**Verification method:** I/A/D/T

**Test goal:** Description of what is to be tested

**Expected result:** What test result is expected for the test to pass

**Test steps:** Step by step instructions on how to perform the test

**Test result:** PASS/FAIL

The test ID starts with the fixed prefix 'TEST'. The prefix is followed by a single letter, which defines the test type / verification method. The last part of the ID is a 3-digits *hexadecimal* number (0..9|A..F), with the first digit identifing the module, the second digit identifing a class / function, and the last digit - the test ordering number for this object. E.g. 'TEST-T-112'. Each test type has its own counter, thus 'TEST-T-112' and 'TEST-A-112' tests are different entities, but they refer to the same object (class or function) within the same module.

The verification method for a requirement is given by a single letter according to the table below:

| **Term**          | **Definition**                                                               |
| :---------------- | :--------------------------------------------------------------------------- |
| Inspection (I)    | Control or visual verification                                               |
| Analysis (A)      | Verification based upon analytical evidences                                 |
| Test (T)          | Verification of quantitative characteristics with quantitative measurement   |
| Demonstration (D) | Verification of operational characteristics without quantitative measurement |

## Tests definition (Analysis)

**Test Identifier:** TEST-A-400

**Requirement ID(s)**: REQ-FUN-400

**Verification method:** A

**Test goal:** All required functionality is implemented and performs correctly.

**Expected result:** All required classes implenting continuous and discrete random distributions are present and function as expected, i.e. all TEST-T-4xy tests defined in this document are passed.

**Test steps:** Analyze the source code of the module [distribution\_classes](../../distribution_classes.py) as well as of the unit-test module [/Tests/UT004\_distribution\_classes](../../Tests/UT004_distribution_classes.py). Execute the mentioned unit-test module.

**Test result:** PASS / FAIL

## Tests definition (Test)

**Test Identifier:** TEST-T-4??

**Requirement ID(s)**: REQ-???-4??

**Verification method:** T

**Test goal:** ?

**Expected result:** ?

**Test steps:** ?

**Test result:** PASS / FAIL

___

## Tests definition (Demonstration)

**Test Identifier:** TEST-D-400

**Requirement ID(s)**: REQ-FUN-407, REQ-FUN-408

**Verification method:** T

**Test goal:** Check implementation of the methods *random*() and *getHistogram*()

**Expected result:** A historgam of the distribution itself (method *getHistogram*()) is similar (almost equal) in shape to the step-wise approximation of the shape of PDF of the distribution. A histogram of a large sample of random numbers generated by the corresponding distribution class resembles the both previous shapes.

**Test steps:** Perform the following procedure with all distributions to be tested.

* Instantiate the respective class with arbitrary chosen parameters
* Generate a sequence of 1000 random number with this instance
* Instantiate 1D statistics class (module *data\_classes*) with that sequence
* Generate a histogram of the sample with the default 20 bins
* Normalize the values (frequences) in each bin by the length of the sequence 1000
* Determine the minimum and maximum central values of the bins and bin width 
* Generate the histrogram of the entire distribution (tested class) using the determined minimum and maximum central values and the number of bins - 20
* For each bin with the cental value $x_k$ (and the same width *S*) manually calculate the value $S * [pdf(x_k - s/2) + pdf(x_k) + pdf(x_k + s/2)] / 3$
* Print out the results of the calculation (3 histograms) on the screen as 6-columns table and compare

**Test result:** PASS / FAIL

## Traceability

For traceability the relation between tests and requirements is summarized in the table below:

| **Requirement ID** | **Covered in test(s)** | **Verified \[YES/NO\]**) |
| :----------------- | :--------------------- | :----------------------- |
| REQ-FUN-400        | TEST-A-400             | NO                       |
| REQ-FUN-401        | TEST-T-4??             | NO                       |
| REQ-FUN-402        | TEST-T-4??             | NO                       |
| REQ-FUN-403        | TEST-T-4??             | NO                       |
| REQ-FUN-404        | TEST-T-4??             | NO                       |
| REQ-FUN-405        | TEST-T-4??             | NO                       |
| REQ-FUN-406        | TEST-T-4??             | NO                       |
| REQ-FUN-407        | TEST-D-400             | NO                       |
| REQ-FUN-408        | TEST-D-400             | NO                       |
| REQ-AWM-400        | TEST-T-4??             | NO                       |
| REQ-AWM-401        | TEST-T-4??             | NO                       |

| **Software ready for production \[YES/NO\]** | **Rationale**        |
| :------------------------------------------: | :------------------- |
| NO                                           | Under development    |